model: hf-causal-experimental #hf-seq2seq #hf-causal-experimental
#tiiuae-falcon-7b tiiuae/falcon-40b-instruct google/flan-ul2 psmathur/orca_mini_13b mosaicml/mpt-30b-instruct h2oai/h2ogpt-gm-oasst1-en-2048-falcon-40b-v2 huggyllama/llama-30b h2oai/h2ogpt-gm-oasst1-en-2048-open-llama-7b
model_args: "pretrained=DAMO-NLP-MT/polylm-13b,trust_remote_code=True,use_accelerate=True" #,load_in_8bit=True"#,do_sample=True,temperature=0.2"
tasks: "summarization_20minutes" #"germanquad_open_qa,x_stance_de,pawsx_de"
prompt_version_per_task: "1" # also allows multiple values, e.g. "1,2,3"
num_fewshot: 0
batch_size: "1"
device: null
output_path: null
limit: null
data_sampling: null
no_cache: true
decontamination_ngrams_path: null
description_dict_path: null
check_integrity: false
write_out: true # true = dump JSON with prompts and completions
output_base_path: "results" # location of JSON dump with predictions+prompts
wandb_on: true
